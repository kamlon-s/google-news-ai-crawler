name: Daily AI News Crawl and Upload

on:
  schedule:
    # Runs daily at 11:45 PM KST (14:45 UTC)
    - cron: '45 14 * * *'
  workflow_dispatch: # Allows manual triggering from GitHub Actions tab

jobs:
  crawl-and-upload:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x' # Use the latest Python 3.x version

    - name: Debug Telegram Environment Variables
      run: |
        echo "TELEGRAM_BOT_TOKEN_SET: ${{ secrets.TELEGRAM_BOT_TOKEN != '' }}"
        echo "TELEGRAM_CHAT_ID_SET: ${{ secrets.TELEGRAM_CHAT_ID != '' }}"

    - name: Install dependencies
      run: pip install -r "requirements.txt"

    - name: Run AI News Crawler and Upload to Supabase
      env:
        # IMPORTANT: These secrets must be configured in your GitHub repository settings.
        # Go to your repository -> Settings -> Secrets and variables -> Actions -> New repository secret
        # Create SUPABASE_URL and SUPABASE_KEY secrets with your actual values.
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
      run: python "crawl_google_news.py"
